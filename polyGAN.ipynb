{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD, Nadam, Adam, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# Change these parameters to match the dimensions of your images\n",
    "input_dims = 100  # Number of random inputs per generated image.\n",
    "\n",
    "# Input image must have the same width and height.\n",
    "# Enter the length of the image in pixels here. Must be a multiple of 4.\n",
    "# Enter 28 for mnist and 32 for cifar\n",
    "img_side = 100\n",
    "n_color_channels = 1  # Number of color channels: 3 for colored images (like cifar) and 1 for grayscale (like mnist).\n",
    "batch_size = 20  # Number of images per batch.\n",
    "epochs = 300  # Number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_folder(folder_name=\"D:\\kavya\\Healthy\", subsample=2000):\n",
    "    img_names = [f for f in os.listdir(folder_name) if not f.startswith('.')]\n",
    "    x = []\n",
    "    for img_name in img_names:\n",
    "        im = cv2.imread(folder_name+\"/\" + img_name, cv2.IMREAD_GRAYSCALE)\n",
    "        x.append(im)\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    x = x.reshape(x.shape[0],x.shape[1],x.shape[2],1)\n",
    "    print(x.shape)\n",
    "    return x[:subsample]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_dim=input_dims, activation=\"tanh\"))\n",
    "    model.add(Dense(64 * (img_side // 4) * (img_side // 4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Reshape((img_side // 4, img_side // 4, 64), input_shape=(64 * (img_side // 4) * (img_side // 4,))))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5), padding=\"same\"))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(n_color_channels, (5, 5), padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), padding='same', input_shape=(img_side, img_side, n_color_channels)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GAN(gen, discrim):\n",
    "    model = Sequential()\n",
    "    model.add(gen)\n",
    "    discrim.trainable = False\n",
    "    model.add(discrim)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(gen_images):\n",
    "    num = gen_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = gen_images.shape[1:]\n",
    "    image = np.zeros((height * shape[0], width * shape[1], shape[2]),\n",
    "                     dtype=gen_images.dtype)\n",
    "    for index, img in enumerate(gen_images):\n",
    "        i = int(index / width)\n",
    "        j = index % width\n",
    "        image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1]] = img[:, :, :]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_images, batch_size=16, epochs=10, display_window=2):\n",
    "    X_train = training_images\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Convert from range (0 to 255) to range (-1 to 1)\n",
    "\n",
    "    d = discriminator()\n",
    "    g = generator()\n",
    "    gan = GAN(g, d)\n",
    "    d_optim = SGD(lr=0.001, momentum=0.5)    # TODO: Try new optimizers. SGD is kinda shitty but fast.\n",
    "    g_optim = SGD(lr=0.001, momentum=0.5)\n",
    "    gan.compile(loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    d.trainable = True\n",
    "    d.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(\"Epoch is \", epoch)\n",
    "        # print(\"Number of batches\", int(X_train.shape[0] / batch_size))\n",
    "        for index in range(X_train.shape[0] // batch_size):\n",
    "            noise = np.random.uniform(-1, 1, size=(batch_size, input_dims))\n",
    "            image_batch = X_train[index * batch_size: (index + 1) * batch_size]\n",
    "            generated_images = g.predict(noise, verbose=0)\n",
    "\n",
    "            if index % display_window == 0:\n",
    "                # Stitch images into one image\n",
    "                image = combine_images(generated_images)\n",
    "                original = combine_images(image_batch)\n",
    "\n",
    "                # Convert pixel intensity back to range (0-255) and cast to int\n",
    "                image = (image * 127.5 + 127.5).astype(np.uint8)\n",
    "                original = (original * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "                zoomfactor = 2  # Zooming levels during display\n",
    "\n",
    "                image = cv2.resize(image, (image.shape[0] * zoomfactor, image.shape[0] * zoomfactor))\n",
    "                original = cv2.resize(original, (original.shape[0] * zoomfactor, original.shape[0] * zoomfactor))\n",
    "                cv2.imshow('Output', image)\n",
    "                cv2.imshow('Input', original)\n",
    "                cv2.waitKey(1)\n",
    "\n",
    "            # print(image_batch.shape, generated_images.shape)\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * batch_size + [0] * batch_size\n",
    "            d_loss = d.train_on_batch(X, y)\n",
    "            noise = np.random.uniform(-1, 1, size=(batch_size, input_dims))\n",
    "            d.trainable = False\n",
    "            g_loss = gan.train_on_batch(noise, [1] * batch_size)\n",
    "            d.trainable = True\n",
    "\n",
    "            # Saving images at the given interval\n",
    "            if epoch % display_window == 0:\n",
    "                cv2.imwrite('D:\\kavya\\code\\outputs\\image' + str(epoch) + \".png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 100, 100, 1)\n",
      "Epoch is  1\n",
      "Epoch is  2\n",
      "Epoch is  3\n",
      "Epoch is  4\n",
      "Epoch is  5\n",
      "Epoch is  6\n",
      "Epoch is  7\n",
      "Epoch is  8\n",
      "Epoch is  9\n",
      "Epoch is  10\n",
      "Epoch is  11\n",
      "Epoch is  12\n",
      "Epoch is  13\n",
      "Epoch is  14\n",
      "Epoch is  15\n",
      "Epoch is  16\n",
      "Epoch is  17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dbe73e8e900b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_from_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-6d3b019316ce>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(training_images, batch_size, epochs, display_window)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mimage_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_window\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GAN\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GAN\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    328\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m                     \u001b[0mouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                 \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_data = load_from_folder(subsample=500)\n",
    "train(training_images= input_data,batch_size=batch_size, epochs=epochs, display_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
